---
title: "surv_proj2"
author: "Lxy"
date: "March 31, 2017"
output: html_document
header includes: \usepackage{amsmath, amsthm, amssymb}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

The first project focuses on employing numerical apporximations from Lindley (1980) and Tierney & Kadane (1986) on survival data which are considered interval-censored. We have considered only a parametric approach assuming the survival data follows a loglogistic distribution model.

For the second project, we will be looking at expanding the scope through the following: 
1. Estimation of the Bayesian parameters with asymmetric loss functions
2. Comparison between Bayesian parametric and non-parametric approach
3. Implementation on methods for interval-censored data in R with package Icens and intcox

### Estimation of Bayesian parameters with asymmetric loss functions
Refer to: Calabria & Pulcini (1996)

Asymmetric loss functions are used to reflect, in most situation of interest, overestimation of a parameter does not produce the same economic consequence as underestimation. both the non-informative prior and informative prior on the reliability level at a prefixed time value are considered.

Bayes approach allows:
* prior information on the parameters of the failure model to be incorporated into the inferential procedure
* considerations on the economic consequences arising from the wrong point estimate to be incorporated into the estimation procedure by using an appropriate loss function

Let \( t_1, t_1, \dots, t_m, t_{m+1}, \dots, t_n\) denote experimental data from a left-truncated exponential distribution, \( f(t) = \theta^{-1}exp[-(t-\eta)/\theta], \ t \geq \eta \geq 0;\ \theta \geq 0  \) collected under a randomly censored sampling with \(m\) items failed at \(t_1, t_2, \dots, t_m\) and \(n-m\) items functioning at \(t_{m+1}, \dots, t_n\).

The likelihood function, give n the sample information is:
\[
l(\eta, \theta) = \theta^{-m} exp[-(X-n\eta)/\theta]
\]
where \(X = \sum_{i=1}^{n} t_i\) is the accumulated observed life

### Posterior distribution
When no prior information is known, the non-informative prior on \(\eta\) and \(\theta\) is
\[g(\eta, \theta)  \propto 1/\theta \]

### Asymmetric loss functions

The loss function \(L(\hat{\alpha}, \alpha)\) provides a measure of financial consequences arising from a wrong estimate \(\hat{\alpha}\) of the unknow quantity \(\alpha\). the choice of the appropriate loss function depends on financial considerations and is independent from the estimation procedure.

The LINEX loss function, introduced by Varian (1975), is one asymmetric loss function which rises approximately exponentially on one side of zero and approximately linearly on the other side.

Under the assumption that the minimal loss occurs at \(\hat{\alpha} = \alpha\), the LINEX loss function can be expressed as:
\[
L_L(\tilde{\alpha}, \alpha) \propto exp[q(\tilde{\alpha}-\alpha)] - q(\tilde{\alpha}-\alpha) - 1, \qquad q \neq 0
\]
The sign of shape parameter \(q\) reflects the direction of the asymmetry, \(q>0\) if overestimation is more serious than underestimation. Magnitude of \(q\) reflects the degree of asymmetry. For small \(|q|\), the LINEX loss function is almost symmetric and nearly quadratic. The Bayes estimate under such a loss, say \(\hat{\alpha}^L\), is not far from the posterior mean.

The posterior expectation of the LINEX loss function is 
\[
E_{\alpha}\{ L_L(\tilde{\alpha}, \alpha)\} \propto exp(q\tilde{\alpha})\ E_{\alpha} \{ exp(-q\alpha)\} - q(\tilde{\alpha} - E_\alpha\{\alpha\}) - 1
\]
where \(E_\alpha \{ f(\alpha)\}\) denotes the expectation of \(f(\alpha)\) with respect to the posterior density \(\pi(\alpha | data)\). The Bayes estimate \(\tilde{\alpha}\) that minimises the expectation above is 
\[
\tilde{\alpha}^L = - \frac{1}{q} ln \big( E_\alpha \{ exp(-q\alpha)\}\big)
\]
provided that \(E_\alpha \{ exp(-q\alpha)\) exists and is finite, Zellner (1986).

Although the LINEX loss function is popular for the estimation of the location parameter, it appears to be not suitable for the estimation of the scale parameter and other quantities (Basu & Ebrahimi (1991) and Parsian & Sanjani Farsipour (1993)). Basu & Ebrahimi (1991) suggested the Modified LINEX loss:
\[
L_M (\tilde{\alpha}, \alpha) \propto exp[q^\prime (\tilde{\alpha}/\alpha-1)] - q^\prime (\tilde{\alpha}/ \alpha -1) - 1 ]
\]
and \(\tilde{\alpha}^M\) that minimises the modified loss function, is the solution of:
\[
E_\alpha\{ \alpha^{-1} exp(q^\prime \tilde{\alpha}^{\Lambda I} / \alpha) \} = exp(q^\prime) E_\alpha \{1/\alpha\}
\]
povided that all the expectations are finite.

The Modified LINEX loss appears to be appropriate in the context of the stimation of \(\theta, \lambda, \rho, R(t_0) \) and \(t_{R_0}\). However the expectations in the modified loss function cannot be solved analytically with respect to the posterior distributions. Thus \(\tilde{\alpha}^M\) cannot be given in a closed form.

Another alternative to the Modififed LINEX is the General Entropy loss proposed by Calabria and Pulcini (1994a):
\[
L_E (\tilde{\alpha}, \alpha) \propto (\tilde{\alpha}/\alpha)^p - p\ ln(\tilde{\alpha}/\alpha) -1
\]
where the minimm occurs at \(\tilde{\alpha} = \alpha\)

When \(p>0\), a postive error \( (\tilde\alpha > \alpha) \) causes more serious consequences than a negative error. The Bayes estimate of \(\alpha\) under the General Entropy loss is in a closed form:
\[
\tilde\alpha^E = [E_\alpha (\alpha^{-p})^{-1/p}]
\]
provided that \(E_\alpha(\alpha^{-p})\) exists and is finite.
Some notes on the estimate above:
* When \(p=1\), the Bayes estimate conicides with the Bayes estimate under the weighted squared-error loss function \( (\tilde\alpha-\alpha)^2/ \alpha\)
* When \( p=-1 \), the Bayes estimate coincides with the Bayes estimate under the Squared Error loss function

To choose the appropriate value of the shape parameter of the selected loss function so that the asymmetry of the loss function reflects the practical situation, the following is proposed:
* when the selected function is the LINEX loss, the value \(q\) is chosen to satisfy
\[
\frac{L_L(\alpha + \Delta, \alpha)}{L_L(\alpha - \Delta, \alpha)} = r, \quad \Delta > 0
\]
where \(r\) is the value of the ratio of the loss for overestimation and the loss for underestimation.

* If the selected function is the Modified LINEX loss or the General Entrophy loss, then we search for the value \(q\prime\) or \(p\) that satisfies
\[
\frac{L(\alpha \cdot \delta, \alpha)}{L_L(\alpha/\delta, \alpha)} = r, \quad \delta > 1
\]
where the \(r\) is the value of the ratio of the loss for an overestimation of \(\delta\) times and the loss for an underestimation of \(1/\delta\) times.

### Comparison of Bayes estimates

Taking expectation over all possible outcomes of the experiment with the unknown random loss \(L(\tilde\alpha, \alpha)\) , the risk function of \(\tilde\alpha\) can be obtained as
\[
RF(\tilde\alpha) = E\{L(\tilde\alpha, \alpha\} = \int L(\tilde\alpha, \alpha) \cdot f(\tilde\alpha)\ d\tilde\alpha
\]
The risk function can be used as an measure of robustness of the Bayes procedure with respect to a wrong choice of the prior distribution or for comparison against classical estimators, i.e. Maximum Likelihood (ML).

The Bayes estimator can be compared to ML estimators in terms of "Relative Efficiency", defined as the raio of the risk function of the ML estimator to the risk function of the corresponding Bayes estimator. Relative Efficiencies greater than 1 are favourable to the Bayes procedure.

Based on the simulation results by Calabria & Pulcini (1996), Bayes estimators based on both non-informative or informative priors are more efficient than ML ones. The result regarding non-informative procedure is expected as the Bayes approach provides point estimators based on the loss function whereas the ML method does not incorporate it.

The informative procedure appears to be quite robust even with wrong prior densities. The relative efficieny of the Bayes estimators under the informative prior is larger than of the non-informative prior, regardless of the accuracy of prior information.

### Linear exponential loss function
Refer to: Chris Bambey Guure et al. (2015)

If a LINEX loss function is used, the Bayes estimator of $\theta$ can be expressed as:
\[
\hat\theta = - \frac{1}{c} ln\, E_\theta\{ exp(-c\theta\}
\]

provided that $E_\theta(.)$ exists and is finite.

The posterior Bayes Estimator, of a LINEX loss function $u = u(exp(-c\alpha), exp(-c\beta))$ is:

\[
\pi^*(\alpha, \beta \mid L_i, R_i) = \frac{\int \int u(exp(-c\alpha), exp(-c\beta)) \pi(\alpha, \beta,L_i, R_i)\, d\alpha\, d\beta}{\int \int \pi(\alpha, \beta, L_i, R_i)\, d\alpha\, d\beta}
\]

where the variable $c$ in function $u(.)$ is the LINEX loss parameter. According to Calabria & Pulcini (1996), $c=\pm0.7$ is used.

The parameters $\hat\alpha$ and $\hat\beta$ can be estimated similarly under the Lindley approximation with the following changes on $u(.)$:

\[
u(\alpha) = e^{-c\alpha},\ u(\beta) = e^{-c\beta},\\
u_1 = -ce^{-c\alpha},\ u_{11} = c^2e^{-c\alpha},\\
u_2 = -ce^{-c\beta}, u_{22} = c^2e^{-c\beta}
\]

Under the Tierney & Kadane procedure, only the $l^*(\alpha^*\beta^*)$ has $u(.)$ which can be expressed as:

\[
l^*(\alpha^*, \beta^*) = l(\alpha, \beta) + \frac{1}{n} ln\,u(exp(-c\alpha),\ exp(-c\beta))
\]




## Bayesian parametric approach
refer to: Gomez, Calle & Oller (2004), Frequentist and Bayesian approaches for interval-censored data

Define interval censoring:
The only information about the survival time \(T\) is that it lies between two observed times \(L\) and \(R\). If the event is only known to be larger or smaller than an observed monitoring time, the data conforms to the current status model or interval censored data (case 1). In experiments with two monitoring times, \(U\) and \(V\) with \(U < V\), where it is only possible to determine whether the event of interest occurs before the first monitoring time, \(T < U\), between the two monitoring times, \(U < T < V\), or after the last monitoring time, \(T > V\). This observable data is know as interval censored data (case 2). Extension of case 1 and 2 models is the case \(k\) model, where \(k\) is a fixed number of monitoring times.

Both Peto (1973) and Turnbull (1976) consider closed intervals, \([L,R]\). Ng (2002) shown that different interpretations of the intervals lead to different likelihood functions, which could imply different nonparametric MLE.

For the frequentist approach, Peto (1973) proposed a method based on maximising the log-likelihood by a suitable constrained Newton-Raphson programmed search. Turnbull (1976) later approaches the more general problem of the analysis of arbitrarily grouped, censored and truncated data and derives an algorithm to obtain the nonparametric estimator of the distribution function. 

The proposed nonparametric estimator for the distribution function is a discrete distribution function that maximises the likelihood over the set of discrete distribution function that maximises the likelihood over set of discrete distributions that are peicewise constant between a finite set of points that depend on the observations. As the estimators are step functions, the behaviour is quite unsmooth and sometimes lack interpretability.

Advantages of Bayesian approach in survival analysis include the direct probabilistic interpreatation of the posterior distribution and the possibility of incorporating prior beliefes about the distribution function. The main drawbacks in the past is due to the difficulty in obtaining the posterior distribution explicitly. This issue has been overcame With new numerical algorithms methods (Markov Chain Monte Carlo) and more computing power.

Let \(T_1, \dots, T_n\) be the potential times for the \(n\) individuals and denote \(D=\{[L_i, R_i],\ 1 \leq i \leq n \}\) as the observed censoring intervals. Assume \(T_1, \dots, T_n\) are independent and identically distributed with density function \(w(t; \theta)\). The likelihood function under noninformative assumption is given by 
\[
L(\theta \mid D) = \prod_{i=1}^n [W(R_i; \theta) - W(L_i; \theta)] = \prod_{i=1}^{n} \int_{L_i}^{R_i} w(u_i; \theta)\ du_i 
\]
where \(W(t; \theta) = Pr(T \leq t; \theta)\)

By means of Bayes theroem and assuming a prior distribution \(p(\theta)\) for \(\theta\), the posterior distribution of \(\theta\) is given by
\[
p(\theta \mid D) = \frac{L(\theta \mid D) \cdot p(\theta)}{\int L(\theta \mid D) \cdot p(\theta)\ d\theta}
\]

The integral in the denominator usually is not in closed form and requires numerical methods to estimate. Smith & Roberts (1993) suggested to use the Gibbs sampler. The unobserved data are reintroduced in the model as further unknowns and this leads to more tractable solutions. The strategy of introducing additional or latent variables in the model is also called the data augmentation algorithm (Tanner & Wong, 1987).

### Data augmentation method

Let \(p(x)\) be the distribution of interest which does not have explicit form and is difficult to sample from. Let \(y\) be an additional variable, which is referred to as latent variable, so that we can sample from \(p(y \mid x)\) and  \(p(x \mid y) \). The data augmentation will sample iteratively from these two conditional distributions.
\begin{enumerate}
\item Given inital value \(x^{(0)}\), draw a value \(y^{(1)}\) from \(p(y \mid x^{(0)})\)
\item With the value  \(y^{(1)}\), draw a value \(x^{(1)}\) from \(p(x \mid y^{(1)})\)
\end{enumerate}

Tanner & Wong (1987) proves that perfoming the two steps above iteratively  will provide pairs \((X^{(i)}, Y^{(i))})\), where \(X^{(i)}\) converges in distribution to a variable \(X\) with distribution \(p(x)\) and \(Y^{(i)}\) converges in distribution to a variable \(Y\) with distribution \(p(y)\).

Employing the approach above to simulate from \(p(\theta \mid D\) given the latent variables (censored times), \(T_1, \dots, T_n\), we have the following:
\begin{enumerate}
\item Sample \(T_i\) from \(p(T_i \mid \theta, D)\) for each \(i\)
\item Since noninformative condition implies that \(p(\theta \mid T_1, \dots, T_n, D) = p(\theta \mid T_1, \dots, T_n)\), sample \(\theta\) from \(p(\theta \mid T_1, \dots, T_n)\) with the \(T_i\) obtained in the first step
\end{enumerate}

Gelfand & Smith (1990) shows that under weak conditions, succesive iterations of the two steps above will provide a sample of parameter \(\theta\) which converges to the posterior distribution of \(\theta\).

The approach can be extended to analysis of regression models where the parameter \(\theta\) is related to some covariates \(x_1, \dots, x_k\) through a link function \(\theta = g(x_i, \beta)\). Then the parameter of interest will be the regression parameter \(\beta\), which can be simulated through Gibbs sampling algorithm as below:
\begin{enumerate}
\item Impute a value \(T_i\) sampled from \(w(t;\theta)\) truncated in the interval \([L_i, R_i\)
\item Update the value of \(\beta\) sampling from the posterior distribution \(p(\beta \mid T_1, \dots, T_n)\) where
\[
p(\beta \mid T_1, \dots, T_n) = \frac{\prod_{i=1}^n w(T_i;\ \theta = g(x_i, \beta)) \cdot p(\beta)}
                                    {\int \prod_{i=1}^n w(T_i;\ \theta = g(x_i, \beta)) \cdot p(\beta)\ d\beta}
\]
where \(p(\beta)\) is the prior density for the regression parameter
\item Update the value of \(\theta = g(x_i, \beta)\)
\end{enumerate}

## Illustration of hierarchical model
Let \(T_i\) be the infection time interval censored in \([L_i, R_i]\). Denote covariate \(x_i\) where \(x_i = 0\) for heavily-treated group and \(x_i = 1\) for lightly treated group.
\[
\begin{align}
\text{Stage 1:}\quad &T_i \sim log\ N(\mu_i, \sigma^2)\ \text{truncated in} [L_i, R_i]\\
                     &\mu_i \sim \beta_0 + \beta_1 \cdot x_i \\
\\
\text{Stage 2:}\quad\ &\beta_0 \sim N(\alpha_0, \sigma_1^2) \\
                      &\beta_1 \sim N(\alpha_1, \sigma_1^2) \\
                      &\sigma^2 \sim IG(0.001, 0.001) \\
\\                      
\text{Stage 3:}\quad\ &\alpha_0 \sim N(0, 1.10^{-6}) \\
                      &\sigma_0^2 \sim IG(0.001, 0.001) \\
                      &\alpha_1 \sim N(0, 1.10^{-6}) \\
                      &\sigma_1^2 \sim IG(0.001, 0.001)
           
\end{align}
\]

The observational model is specified in Stage 1, where each individual is assumed to be a log-normal model truncated in the censoring interval. The mean \(\mu_i\) is assumed to be equal to \(\beta_0\) for heavily treated group and dqualt to \(\beta_0 + \beta_1\) for lightly-treated group.

The normal prior distributions for these parameters are specified in stage 2 and an inverse gamma distribution for the variance.

In stage 3, the vague priors are specified for the hyperparameters.

## Nonparametric Bayesian estimation from interval censored data using Monte Carlo methods
refer to: Calle & Gomez (2001)

Susarla & Van Ryzin (1976) first derived the nonparametric Bayesian estimator of the survival function for right-censored data, based on the class of Dirichlet proccesses introudced by Ferguson (1973). They proved that their estimators are asympotically equivalent and has better small sample properties than Kaplan-Meir estimator (Rai et a, 1980).

However, the extension of their approach to more complext censoring situtations, i.e. interval censoring is not straightforward. Since the estimation of the survival curve cannot be acheived explicitly, computing intensive methods can provide a solution. Doss (1994) propose a Gibbs sampling algorithm to deal with interval censoring based on the simulation of samples from the Dirichlet process.

Calle & Gomez (2001) proposed to expand the usage of Susarla & Van Ryzin (1976) estimator for interval censoring scheme by using Markov Chain Monte Carlo methods and introducing latent count variables. The proposed Bayesian estimator can be interpreted as a way of 'shrinking' Turnbull's nonparametric estimator to a smooth parametric family.

### Nonparametric Bayesian method

Let \(T\) be a positive random variable representing the time until the cocurence of a certain event \(E\) with unknown survival function \(S\). Our goal is to estimate the random survival function \(S(t) = Pr(T>t)\) based on the interval-censored data and assuming a Dirichlet process as a prior distribution. \(\hat{S}(t) = E(S(t) | D)\) is proposed as a nonparametric estimator of \(S\) , where \(E\) denotes expectation with respect to the posterior distribution of the Dirichlet process. \(\hat{S}\) minimises the posterior expected lost.
\[
L(\hat{S}, S) = \int_0^\infty (\hat{S}(t) - S(t))^2 dg(t)
\]

When data are uncensored, Ferguson (1973) showed that the nonparametric Bayesian estimator of the survival function can be expressed as a linear combination of the prior guess \(S_0\) and the emprical survival function \(S_n\):
\[
\hat{S}(t) = \frac{\beta}{\beta+n}S_0(t) + \frac{n}{\beta+n}S_n(t)
\]
where \(\beta\) is the parameter of the Dirichlet prior.

Susarla & Van Ryzin (1976) derived the nonparametric Bayesian estimator for the survival function \(S(t)\) based on the right-censored data. Under a right censoring scheme, for each time \(t\) the exact number of obeservations that have failed until that time is known. However, this number of failures is unknown under an interval censoring scheme. Thus, a sample based approach is proposed, by deriving a sample from the posterior distribution of \(S(t_j),\ 1 \leq j \leq r\), where \(t_j\) is the partition induced by the endpoints of the censoring intervals.

### Notation and prior distributions
Let \(n\) interval-censored survival data denoted by \(D = \{[T_{L^i}, T_{R^i}],\ 1 \leq i \leq n\}\). \(T_{L^i}\) is the last observed time for the \(i\)th individual before the event \(E\) occured and \(T_{R^i}\) indicates the first time the event \(E\) has been observed.

Assumed that there is some prior belief in the shape of the survival function by the parameter model \(S_0\). Then, we can express some uncertainty in the prior belief by assuming a Dirichlet process prior \(P\) around \(S_0\), with parameter measure \(\alpha\). The parameter function can be expressed as \(\alpha(t, +\infty) = \beta S_0(t)\), where \(\beta > 0\), representing the measure of faith in the prior guess \(S_0\).

Let \(0 = t_0 < t_1 < \dots <t_r = +\infty\) be the partition of the real line induced by endpoints of the censoring interval in \(D\). Denote by \(w\), the vector whose \(j\)th component is \(w_j = Pr(T \in (t_{j-1}, t_j]) = S(t_{j-1}) - S(t_j)\).

The joint density of \(w\) is given by the Dirichlet distribution
\[
g(\boldsymbol{w} | \alpha_1, \dots, \alpha_r) = \frac{\Gamma(\alpha_1, \dots, \alpha_r)}{\Gamma(\alpha_1) \dots \Gamma(\alpha_r)} \Bigg( \prod_{j=1}^{r-1} w_{j}^{\alpha_j - 1} \Bigg) \Bigg( 1 - \sum_{j=1}^{r-1} w_{j} \Bigg)^{\alpha_r-1}
\]
where \(\alpha_j = \beta(S_0(t_{j-1}) - S_0(t_j)\)

For each individual \(i\), we have the potential survivla time \(T^i\) and the vector \(\boldsymbol{\delta_i} = (\delta_1^i, \dots ,\delta_r^i)\), where \(\delta_j^i = \boldsymbol{1} \{T^i \in (t_{j-1}, t_j] \}\). As the event of interest acan occur in one and only one of these intervals, the distribution of \(\boldsymbol{\delta}^i\) conditioned on \(\boldsymbol{w}\) is multinomial distribution of sample size 1,
\[
h(\boldsymbol{\delta}^i | \boldsymbol{w}) = \prod_{j=1}^r w_j^{\delta_j^i} \quad where \ \sum_{j=1}^r \delta_j^i = 1
\]

### Posterior and conditional distributions

The sample from the posterior distribution of the vector \(\boldsymbol{w}\) given the data \(D\) can be obtained through the Gibbs sampler methodology. Since the posterior distribution of the vector \(\boldsymbol{w}\) given a sample from a Dirichlet process, only depends on the number of events, \(n_j\) that fall in \((t_{j-1}, t_j]\) and not on where they fall exactly (Doksum, 1974), they propose to derive the posterior distribution of \(\boldsymbol{w}\)  by introducing the vector \(\boldsymbol{n} = (n_1, \dots , n_r\) in the model as latent variable. Denote the posterior condition distribution of \(\boldsymbol{n}\) given \(\boldsymbol{w}\) by \([\boldsymbol{n} |(\boldsymbol{w}, D ]\) and the posterior conditional distribution of \(\boldsymbol{w}\) given \(\boldsymbol{n}\) by \([\boldsymbol{w} |(\boldsymbol{n}, D ]\).

The two steps of the Gibbs algorithm for the \(l\)th iteration are simplified as follows:
\begin{enumerate}
\item Simulate \(\boldsymbol{n}^{(l)}\) from \([\boldsymbol{n} |(\boldsymbol{w}, D ]\) 
\item Simulate \(\boldsymbol{w}^{(l+1)}\) from \([\boldsymbol{w} |(\boldsymbol{n}, D ]\)
\end{enumerate}

It was shown under rather weak conditions (Gelfand & Smith, 1990) that the Markovian sequence \((\boldsymbol{w}^{(l+1)}, \boldsymbol{n}^{(l)})\) converges to an equilibrium distribution that is the joint distribution of \((\boldsymbol{w},  \boldsymbol{n})\). After generating \(m\) samples from Gibbs sampling chains, we can approximate the marginal posterior distribution of \(\boldsymbol{w}\) by the empirical smapling distribution or by using the average of the posterior conditional distributions of \(\boldsymbol{w}\) given \(\boldsymbol{n}\).


### Algorithm and implementation

The algorithm consists on \(k\) successive simulations from the corresponding full conditional distributions
\begin{enumerate}
\item Initial values: Define the initial probabilities \(\boldsymbol{w}^{(0)} = (w_1^{(0)}, \dots, w_r^{(0)}) \)
\item Update \(\boldsymbol{n}\): For each iteration \(l = 1, \dots, k\) and for each individual \(i=1, \dots, n\), generate \(\boldsymbol{\delta}^i\) from a truncated multinomial of sample size 1 and parameter \(\boldsymbol{w}^{(0)\). Compute \(n_j^{(0)} = \sum_{i=1}^n \delta_j^i\), the number of events in each interval \((t_{j-1}, t_j)\)
\item Update \(\boldsymbol{w}\): Generate \(\boldsymbol{w}^{(1)} = (w_1^{(1)}, \dots, w_r^{(1)})\) from a Dirichlet distribution of parameter vector \((\alpha_1+n_1^{(0)}, \dots,  \alpha_r+n_r^{(0)})\)
\item Replace \(\boldsymbol{w}^{(0)}\) by \(\boldsymbol{w}^{(1)}\) and return to Step 1. Repeat Steps 1 and 2 until convergence.
\end{enumerate}

Gelman & Rubin (1992) suggested to discard the first \(k_0\) iterations of each sequence to diminish the effect of the starting values.
The choice of the prior guess, \(S_0(t)\) can be chosen by modeling the prior knowldege of the problem or following an empirical Bayesian approach. Rai et al. (1980) suggested to use \(\beta = \sqrt n\) as a consistent estimator for the precision parameter. The Bayesian estimator is shown to be close to the nonparametric maximum likelihood estimator as the prior weight, \(\beta \to 0\).  As the prior weight increases, the Bayesian estimator approaches the parametric prior guess, \(S_0(t)\).

### Discussion on the methods

Bayesian approaches have the advantage of allowing incorporation of external knowledge about the process. This is important when the information provided by the data due to scarcity or heavy censoring. The proposed approach also produces a sample of posterior distribution of the parameter of interest, which can be extended to obtain other posterior estimates, i.e. posterior quantiles and  posterior hazard rates.

The proposed approach only consider the number of events in each interval with the use of the Dirichlet process. However its use is not recommended in the approach based on the estimation of the hazard function (Sinha & Dey, 1997).

Further extensions would include incorporating covariates and to fit the entire dat set into a single model. One possible approach that was suggested was using hierarchical Bayesian models (Lindley & Smith, 1972) with interval censoring patterns.

### Frequentist approach to nonparametric survival function estimation

Refer to Zhigang & Jianguo, Interval Censoring, 2010
Assumed non-informative interval censoring, i.e.
\[
P(T \leq t \mid L=l,\ R=r,\ L<T\leq R) = P(T \leq t \mid l < T \leq r)
\]

Let \(\{I_i\}_{i=1}^{n}\) where \(I_i = (L_i, R_i]\), the interval that containe the unobserved \(T\). Let \(\{t_j\}_{j=0}^{m+1}\) denote the unique ordered elements of \(\{0, \{L_i\}_{i=1}^{n},  \{R_i\}_{i=1}^{n}, \infty\}\), \(\alpha_{ij}\) is the indicator of the event \((t_{j-1}, t_j] \subseteq I_i \) and \(p_j = S(t_{j-1})-S(t_j)\).

The likelihood function for \(\boldsymbol{p} = (p_1, \dots, p_{m+1})^\prime\) and is proportional to 
\[
L_s (p) = \prod_{i=1}^n \big[ S(L_i) - S(R_i) \big] = \prod_{i=1}^n \sum_{j=1}^{m+1} \alpha_{ij}\ p_j
\]
with the constraint 
\(\sum_{j=1}^{m+1} p_j = 1\) and \(p_j \geq 0\ ,\ j=1, \dots\ , m+1\)

There are several methods for maximising \(L_s (p) \) with respect to \(\boldsymbol{p}\).
The first and simplest one is the self-consistency algorithm given in Turnbull (1976) based on
\[
\hat{S}(t) = \frac{1}{n} E \big[ \sum_{i=1}^n I(T_i > t) \mid \hat{S}, I_1, \dots, I_n \big]
\]
which is essentially an application of the EM algorithm (Dempster & Laird, 1977). By iterating the equation below till convergence, we can obtain \(\hat{S}\)
\[
p_j^{new} = \frac{1}{n} \sum_{i=1}^n \frac{\alpha_{ij}\ p_j^{old}}{\sum_{l=1}^{m+1} \alpha_{il}\ p_l^{old}}
\]
Drawback is the slow convergence rate.

Second approach is to maximise \(L_S(\boldsymbol{p})\) through iterative convex minorant (ICM) algorithm introduced by Groeneboom & Wellner (1992) and improved by Jongbloed (1998), which converges faster than the self-consistency algorithm.

Third approach is to use EM-ICM algorithm by Wellner & Zhan (1997), which is a hybrid of the two methods above and the fastest algorithm.

The algorithms above may yield multiple solutions, i.e. the NPMLE (Nonparametric MLE) may not be unique. One sufficient condition for uniqueness is that the log-likelihood is strictly concave, i.e. Hessian \(H\) is strictly negative definite. We may also employ the Kuhn-Tucker conditions (Gentleman & Geyer, 1994) to check if the solutions are NPMLE, i.e.
\[
\sum_{j=1}^{m+1} p_j = 1 \\
p_j \geq 0\ ,\ \mu_j\ p_j = 0\ ,\ \mu_j \geq 0 \\
\frac{\partial}{\partial p_j} \Bigg\{ l(p) + \sum_{j=1}^{m+1} p_j (\mu_j - \mu_0)\Bigg\} = d_j + \mu_j - \mu_0 = 0 \\
\text{for}\ j =1 , \dots, m+1\ \text{and}\ \mu_j\ \text{is the Lagrange multipliers}
\]

The difference between right censoring and interval censoring is that the NPMLE of a survival function based on a right censored data can be derived by Kaplan-Meier (KM) closed form estimate. Interval censoring induces many challengeing problems in large sample  studies as the use of counting process technique is quite difficult and the martingale theory cannot be applied.

It has been shown that for interval-censored data, \(\hat{S}\) is strongly consistent (Yu & Wong, 2000).  However, \(\hat{S}(t)\) converges only in the rate of \(n^{1/3}\) and the limiting distribution is non-normal (Geskus & Groeneboom, 1999). This differs from the usual \(n^{1/2}\) convergence rate and the limiting normal distribution of KM estimate. 

The R package Icens of Gentleman & Vandal (2008) covers the algorithms above to estimate NPMLE.

### Frequentist approach to parametric models

Using the same maximum likelihood function as the Bayes parametric approach, we have the following.

Let \(T_1, \dots, T_n\) be the potential times for the \(n\) individuals and denote \(D=\{[L_i, R_i],\ 1 \leq i \leq n \}\) as the observed censoring intervals. Assume \(T_1, \dots, T_n\) are independent and identically distributed with density function \(w(t; \theta)\). The likelihood function under noninformative assumption is given by 
\[
L(\theta \mid D) = \prod_{i=1}^n [W(R_i; \theta) - W(L_i; \theta)] = \prod_{i=1}^{n} \int_{L_i}^{R_i} w(u_i; \theta)\ du_i 
\]
where \(W(t; \theta) = Pr(T \leq t; \theta)\)

### Comparison between the parametric and nonparametric frequentist approach

If there is scientific or empirical knowledge, the non-parametric approach may represent an important loss of efficiency, specially if the the variable is heavily censored. 

Parametric assumptions are difficult to assess based on a censored sample. It involves the risk of deriving inconsistent estimators for the parameters of interest. If the parametric model does not fit suitably, it might lead to inaccurate conclusions.

Parametric model has the advantage to describe different parameter based quantities, hazard function at different times.


## Methods for interval censored data and implementation in R

















## Uncertainty in repeated measurement of a small non-negative quantity
refer to: Response from the Analytical Method Committee's (AMC) to Willink's paper 'Uncertatinty in repeated measurement of a small non-negative quantity: explanation and discussion of Bayesian methodology' (2010)

It was stated that neither the Bayesisan nor the frequentits frameworks provides a unique 95% CI. In the Bayesian approach, any interval that includes 95% of the posterior probability may be taken as a 95% CI. In the frequentist approach, any interval with 95% coverage probability will qualify. Here the frequentist CI is based on Student's t, repeated or discarded when the netire interval is below zero.

Some strengths and weaknesses of the two approaches:

\begin{tabular}{ c c c }
Content & Frequentist & Bayesian maximum density \\
Coverage properties & Conservative, coverage is always at least 95%, but rises to 97.5% when the true value is near zero &  Average coverage is 95%, but coverage near zero varies a little from 95% in both directions \\
Interval width & reduces to zero at \(\bar{x} \sqrt{n}/s \leq -t_{\alpha/2}\) & always positive, even when the measure value is negative \\
Calculation procedure & Simple, using \(t\)-tables, with decision point at \(\bar{x} \sqrt{n}/s \leq -t_{\alpha/2}\) & Requires spreadsheet or statistical software
\end{tabular}

In  general, the Bayesian maximum density interval will offer advantages in the 'common sense' size of the interval at the expense of more complex computation than the frequentist interval.
